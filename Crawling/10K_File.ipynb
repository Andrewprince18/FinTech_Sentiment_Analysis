{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Part1&2**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **匯入模組**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "匯入標準庫及第三方模組，用來處理時間、資料結構、路徑管理、HTTP 請求和 HTML 解析等功能。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date  # 導入日期模組\n",
    "import time  # 導入時間模組\n",
    "from collections import namedtuple  # 導入命名元組\n",
    "from pathlib import Path  # 導入路徑處理模組\n",
    "from typing import List  # 導入類型提示\n",
    "from urllib.parse import urljoin  # 導入URL合併功能\n",
    "import random  # 導入隨機數模組\n",
    "\n",
    "import requests  # 導入requests庫，用於發送HTTP請求\n",
    "from bs4 import BeautifulSoup  # 導入BeautifulSoup庫，用於解析HTML\n",
    "from requests.adapters import HTTPAdapter  # 導入HTTP適配器\n",
    "from urllib3.util.retry import Retry  # 導入重試功能\n",
    "import pandas as pd  # 導入pandas庫，用於數據處理\n",
    "\n",
    "# SEC搜索API的端點\n",
    "SEARCHAPIENDPOINT = \"https://efts.sec.gov/LATEST/search-index\"\n",
    "# SEC存檔的基本URL\n",
    "ARCHIVESBASEURL = \"https://www.sec.gov/Archives/edgar/data\"\n",
    "# 每次請求之間的休眠時間\n",
    "SLEEPTIME = 0.2\n",
    "# 最大重試次數\n",
    "MAXRETRIES = 10\n",
    "# 日期格式\n",
    "DATE_FORMAT_TOKENS = \"%Y-%m-%d\"\n",
    "# 查詢的開始日期\n",
    "AFTER_DATE = date(2000, 1, 1)\n",
    "# 查詢的結束日期（今天）\n",
    "BEFORE_DATE = date.today()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **重試機制**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用 Retry 來設定 HTTP 請求的重試機制，包括重試的次數、延遲時間及應對的錯誤代碼列表（如403、500等）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 設定重試策略\n",
    "retries = Retry(\n",
    "    total=MAXRETRIES,  # 設定最大重試次數\n",
    "    backoff_factor=SLEEPTIME,  # 設定每次重試之間的間隔時間，根據後退因子來計算\n",
    "    status_forcelist=[403, 500, 502, 503, 504],  # 當響應狀態碼為這些值時，會觸發重試\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **定義常數與命名元組**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定義一些檔案名常數，並使用 namedtuple 定義一個結構 FilingMetadata，用來儲存每筆年報的相關資訊。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 設定根保存文件夾名稱\n",
    "ROOT_SAVE_FOLDER_NAME = \"test\"\n",
    "\n",
    "# 設定提交的完整文檔檔名\n",
    "FILING_FULL_SUBMISSION_FILENAME = \"full-submission.txt\"\n",
    "\n",
    "# 設定提交詳細信息檔名的前綴\n",
    "FILING_DETAILS_FILENAME_STEM = \"filing-details\"\n",
    "\n",
    "# 定義一個命名元組，用來儲存提交的元數據\n",
    "FilingMetadata = namedtuple(\n",
    "    \"FilingMetadata\",  # 命名元組的名稱\n",
    "    [\n",
    "        \"cik\",  # 公司在美國證券交易委員會的中央索引鍵\n",
    "        \"file_date\",  # 提交的日期\n",
    "        \"period_end\",  # 財務報表期間結束日期\n",
    "        \"accession_number\",  # 文件的登記號碼\n",
    "        \"full_submission_url\",  # 完整提交文檔的URL\n",
    "        \"filing_details_url\",  # 提交詳細信息的URL\n",
    "        \"filing_details_filename\",  # 提交詳細信息的文件名\n",
    "    ],\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **建立搜尋請求**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "建立搜尋請求的函式，根據公司代號 (ticker)、檔案類型（例如 \"10-K\"）、開始與結束日期等參數生成搜尋請求。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def form_request(\n",
    "    ticker: str,  # 股票代碼，例如 \"AAPL\" 表示蘋果公司\n",
    "    filing_types: List[str],  # 一個列表，包含要查詢的提交類型，例如 [\"10-K\", \"10-Q\"]\n",
    "    start_date: str,  # 查詢的開始日期，格式為 \"YYYY-MM-DD\"\n",
    "    end_date: str,  # 查詢的結束日期，格式為 \"YYYY-MM-DD\"\n",
    "    start_index: int,  # 查詢的起始索引，用於分頁\n",
    "    query: str,  # 用於查詢的關鍵字，通常是附加的搜尋條件\n",
    ") -> dict:  # 函數返回一個字典\n",
    "    # 構建請求字典，包含查詢的參數\n",
    "    request = {\n",
    "        \"dateRange\": \"custom\",  # 指定日期範圍為自定義\n",
    "        \"startdt\": start_date,  # 開始日期\n",
    "        \"enddt\": end_date,  # 結束日期\n",
    "        \"entityName\": ticker,  # 公司名稱或股票代碼\n",
    "        \"forms\": filing_types,  # 提交類型\n",
    "        \"from\": start_index,  # 起始索引\n",
    "        \"q\": query,  # 查詢的關鍵字\n",
    "    }\n",
    "    return request  # 返回構建好的請求字典\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **提取年報的元數據**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "filing_metadata 函式根據搜尋結果 hit 生成年報的詳細信息，並且構建相關 URL 用來下載完整年報和詳細資料。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filing_metadata(hit: dict) -> FilingMetadata:\n",
    "    # 從 hit 字典中提取必要的資料\n",
    "    accession_number, filing_details_filename = hit[\"_id\"].split(\":\", 1)  # 分割出 accession number 和 filing details filename\n",
    "    cik = hit[\"_source\"][\"ciks\"][-1]  # 提取 CIK (中央索引鍵)\n",
    "    file_date = hit[\"_source\"][\"file_date\"]  # 提取文件日期\n",
    "    period_ending = hit[\"_source\"][\"period_ending\"]  # 提取期間結束日期\n",
    "    accession_number_no_dashes = accession_number.replace(\"-\", \"\", 2)  # 移除 accession number 的前兩個短橫\n",
    "\n",
    "    # 基本的提交 URL 組合\n",
    "    submission_base_url = f\"{ARCHIVESBASEURL}/{cik}/{accession_number_no_dashes}\"\n",
    "    full_submission_url = f\"{submission_base_url}/{accession_number}.txt\"  # 完整的提交文件 URL\n",
    "    filing_details_url = f\"{submission_base_url}/{filing_details_filename}\"  # 提交詳細信息的 URL\n",
    "\n",
    "    # 設定提交詳細信息的文件名，將 .htm 擴展名替換為 .html\n",
    "    filing_details_filename_extension = Path(filing_details_filename).suffix.replace(\n",
    "        \"htm\", \"html\"\n",
    "    )\n",
    "    filing_details_filename = (\n",
    "        f\"{FILING_DETAILS_FILENAME_STEM}{filing_details_filename_extension}\"  # 使用定義的文件名幹\n",
    "    )\n",
    "\n",
    "    # 返回一個 FilingMetadata 實例\n",
    "    return FilingMetadata(\n",
    "        cik,\n",
    "        file_date,\n",
    "        period_ending,\n",
    "        accession_number=accession_number,\n",
    "        full_submission_url=full_submission_url,\n",
    "        filing_details_url=filing_details_url,\n",
    "        filing_details_filename=filing_details_filename,\n",
    "    )\n",
    "\n",
    "# 用於儲存要下載的 filings 的列表\n",
    "filings_to_download: List[FilingMetadata] = []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **抓取年報網址**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 該函式負責從 SEC API 抓取指定公司、年份和年報類型的結果，並儲存在 filings_to_download 列表中。\n",
    "- 它會自動處理網路錯誤並重試請求，並支持過濾是否包含修訂檔（/A）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filing_urls(\n",
    "    filing_type: str,\n",
    "    ticker: str,\n",
    "    num_filings_to_download: int,\n",
    "    after_date: str,\n",
    "    before_date: str,\n",
    "    include_amends: bool,\n",
    "    query: str = \"\",\n",
    ") -> List[FilingMetadata]:\n",
    "    # 設定起始索引\n",
    "    start_index = 0\n",
    "\n",
    "    # 建立一個會話客戶端以管理 HTTP 請求\n",
    "    client = requests.Session()\n",
    "    client.mount(\"http://\", HTTPAdapter(max_retries=retries))  # 設定重試機制\n",
    "\n",
    "    try:\n",
    "        # 當下載的 filings 數量少於所需數量時，持續請求\n",
    "        while len(filings_to_download) < num_filings_to_download:\n",
    "            # 建立請求的有效負載\n",
    "            payload = form_request(\n",
    "                ticker,\n",
    "                [filing_type],\n",
    "                after_date,\n",
    "                before_date,\n",
    "                start_index,\n",
    "                query\n",
    "            )\n",
    "            # 設定請求標頭\n",
    "            headers = {\n",
    "                \"User-Agent\": \"XXXXX@gmail.com\",\n",
    "                \"Accept-Encoding\": \"gzip, deflate\",\n",
    "                \"Host\": \"efts.sec.gov\",\n",
    "            }\n",
    "            # 發送 GET 請求\n",
    "            resp = client.get(\n",
    "                SEARCHAPIENDPOINT, params=payload, headers=headers, verify=False\n",
    "            )\n",
    "            resp.raise_for_status()  # 檢查請求是否成功\n",
    "            queryresults = resp.json()  # 解析 JSON 響應\n",
    "            print(queryresults)  # 輸出查詢結果\n",
    "\n",
    "            queryhits = queryresults[\"hits\"][\"hits\"]  # 提取查詢命中結果\n",
    "            print(queryhits)  # 輸出查詢命中結果\n",
    "\n",
    "            if not queryhits:  # 如果沒有命中結果，則停止查詢\n",
    "                break\n",
    "\n",
    "            # 遍歷所有命中結果\n",
    "            for hit in queryhits:\n",
    "                filing_type = hit[\"_source\"][\"file_type\"]  # 提取提交類型\n",
    "\n",
    "                is_amend = filing_type[-2:] == \"/A\"  # 檢查是否為修訂\n",
    "                if not include_amends and is_amend:  # 如果不包含修訂且為修訂，則跳過\n",
    "                    continue\n",
    "\n",
    "                if not is_amend and filing_type != filing_type:  # 如果不是修訂且類型不匹配，則跳過\n",
    "                    continue\n",
    "\n",
    "                metadata = filing_metadata(hit)  # 提取元數據\n",
    "                filings_to_download.append(metadata)  # 將元數據添加到列表中\n",
    "\n",
    "            # 如果已經下載到所需的 filings 數量，則返回結果\n",
    "            if len(filings_to_download) == num_filings_to_download:\n",
    "                return filings_to_download\n",
    "\n",
    "            query_size = queryresults[\"query\"][\"size\"]  # 獲取查詢結果的大小\n",
    "            start_index += query_size  # 更新起始索引，以便進行下一次查詢\n",
    "\n",
    "            time.sleep(SLEEPTIME)  # 暫停一段時間，以遵循 API 請求限制\n",
    "    finally:\n",
    "        client.close()  # 關閉客戶端連接\n",
    "\n",
    "    return filings_to_download  # 返回已下載的 filings 列表\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **解析 HTML 檔案中的相對路徑**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "該函式將 HTML 檔案中的相對 URL 轉換為絕對 URL，確保下載的檔案包含正確的鏈接和圖片資源。\n",
    "- filing_text：這個變數應該包含了一段從 SEC 申報文件中提取的 HTML 文本。通常這是通過 HTTP 請求從 SEC 網站下載的內容。\n",
    "- \"html.parser\"：這個參數指定使用 Python 內建的 HTML 解析器。BeautifulSoup 支持多種解析器，包括 lxml 和 html5lib，這裡使用的是標準的 HTML 解析器。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resolve_relative_urls(filing_text: str, download_url: str) -> str:\n",
    "    # 使用 BeautifulSoup 解析 HTML 文本\n",
    "    soup = BeautifulSoup(filing_text, \"html.parser\")\n",
    "    # 獲取基本 URL，去掉下載 URL 的最後一部分以建立基礎路徑\n",
    "    base_url = f\"{download_url.rsplit('/', 1)[0]}/\"\n",
    "\n",
    "    # 遍歷所有帶有 href 屬性的超連結\n",
    "    for url in soup.find_all(\"a\", href=True):\n",
    "        # 如果 href 以 # 或 http 開頭，則跳過\n",
    "        if url[\"href\"].startswith(\"#\") or url[\"href\"].startswith(\"http\"):\n",
    "            continue\n",
    "        # 將相對 URL 轉換為絕對 URL\n",
    "        url[\"href\"] = urljoin(base_url, url[\"href\"])\n",
    "\n",
    "    # 遍歷所有帶有 src 屬性的圖片\n",
    "    for image in soup.find_all(\"img\", src=True):\n",
    "        # 將相對的圖片來源轉換為絕對 URL\n",
    "        image[\"src\"] = urljoin(base_url, image[\"src\"])\n",
    "\n",
    "    # 如果 soup 的原始編碼為 None，則返回 soup\n",
    "    if soup.original_encoding is None:\n",
    "        return soup\n",
    "\n",
    "    # 否則，返回以原始編碼編碼的 HTML 字符串\n",
    "    return soup.encode(soup.original_encoding)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **下載年報**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_filings(\n",
    "    download_folder: Path,\n",
    "    ticker: str,\n",
    "    filing_type: str,\n",
    "    num_filings_to_download: int,\n",
    "    after_date: str, \n",
    "    before_date: str,\n",
    "    include_filing_details: bool,\n",
    ") -> None:\n",
    "    # 創建一個 requests 的 Session，以便重複使用連接\n",
    "    client = requests.Session()\n",
    "    # 設定 HTTP 和 HTTPS 的重試機制\n",
    "    client.mount(\"http://\", HTTPAdapter(max_retries=retries))\n",
    "    client.mount(\"https://\", HTTPAdapter(max_retries=retries))\n",
    "    \n",
    "    try:\n",
    "        # 遍歷要下載的每個申報文件\n",
    "        for filing in filings_to_download:\n",
    "            try:\n",
    "                # 嘗試下載完整的申報文件\n",
    "                download(\n",
    "                    client,\n",
    "                    download_folder,\n",
    "                    ticker,\n",
    "                    filing.accession_number,\n",
    "                    filing_type,\n",
    "                    filing.full_submission_url,\n",
    "                    FILING_FULL_SUBMISSION_FILENAME,\n",
    "                )\n",
    "            except requests.exceptions.HTTPError as e:\n",
    "                # 如果下載過程中出現 HTTP 錯誤，則跳過該文件\n",
    "                print(\n",
    "                    \"Skipping full submission download for \"\n",
    "                    f\"'{filing.accession_number}' due to network error: {e}.\"\n",
    "                )\n",
    "\n",
    "            # 如果需要下載申報詳細信息\n",
    "            if include_filing_details:\n",
    "                try:\n",
    "                    # 嘗試下載申報詳細信息\n",
    "                    download(\n",
    "                        client,\n",
    "                        download_folder,\n",
    "                        ticker,\n",
    "                        filing.accession_number,\n",
    "                        filing_type,\n",
    "                        filing.filing_details_url,\n",
    "                        filing.filing_details_filename,\n",
    "                        resolve_urls=True,\n",
    "                    )\n",
    "                except requests.exceptions.HTTPError as e:\n",
    "                    # 如果下載過程中出現 HTTP 錯誤，則跳過該文件\n",
    "                    print(\n",
    "                        f\"Skipping filing detail download for \"\n",
    "                        f\"'{filing.accession_number}' due to network error: {e}.\"\n",
    "                    )\n",
    "    finally:\n",
    "        # 確保在結束時關閉 Session\n",
    "        client.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download(\n",
    "    client: requests.Session,\n",
    "    download_folder: Path,\n",
    "    ticker: str,\n",
    "    accession_number: str,\n",
    "    filing_type: str,\n",
    "    download_url: str,\n",
    "    save_filename: str,\n",
    "    *,\n",
    "    resolve_urls: bool = False,\n",
    ") -> None:\n",
    "    # 設定 HTTP 請求的標頭\n",
    "    headers = {\n",
    "        \"User-Agent\": \"XXXXX@gmail.com\" ,  # 用戶代理，應用發送請求的身份\n",
    "        \"Accept-Encoding\": \"gzip, deflate\",  # 接受的編碼格式\n",
    "        \"Host\": \"www.sec.gov\",  # 請求的主機\n",
    "    }\n",
    "    \n",
    "    # 發送 GET 請求以獲取文件\n",
    "    resp = client.get(download_url, headers=headers)\n",
    "    # 檢查請求是否成功，若不成功則引發異常\n",
    "    resp.raise_for_status()\n",
    "    \n",
    "    # 獲取返回的內容\n",
    "    filing_text = resp.content\n",
    "    \n",
    "    # 如果需要解析相對 URL 並且文件類型是 HTML\n",
    "    if resolve_urls and Path(save_filename).suffix == \".html\":\n",
    "        filing_text = resolve_relative_urls(filing_text, download_url)\n",
    "\n",
    "    # 構建保存文件的完整路徑\n",
    "    save_path = (\n",
    "        download_folder\n",
    "        / ROOT_SAVE_FOLDER_NAME\n",
    "        / ticker\n",
    "        / filing_type\n",
    "        / accession_number\n",
    "        / save_filename\n",
    "    )\n",
    "    \n",
    "    # 創建所有父目錄（如果尚不存在）\n",
    "    save_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    # 寫入獲取的文件內容\n",
    "    save_path.write_bytes(filing_text)\n",
    "\n",
    "    # 等待一段時間以避免過於頻繁的請求\n",
    "    time.sleep(SLEEPTIME)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **調用函數以獲取指定條件的 10-K 申報文件的 URL**\n",
    "\n",
    "抓取美國蘋果公司：2012-2023年之間的年報資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[FilingMetadata(cik='0000320193', file_date='2013-10-30', period_end='2013-09-28', accession_number='0001193125-13-416534', full_submission_url='https://www.sec.gov/Archives/edgar/data/0000320193/000119312513416534/0001193125-13-416534.txt', filing_details_url='https://www.sec.gov/Archives/edgar/data/0000320193/000119312513416534/d590790d10k.htm', filing_details_filename='filing-details.html'),\n",
       " FilingMetadata(cik='0000320193', file_date='2017-11-03', period_end='2017-09-30', accession_number='0000320193-17-000070', full_submission_url='https://www.sec.gov/Archives/edgar/data/0000320193/000032019317000070/0000320193-17-000070.txt', filing_details_url='https://www.sec.gov/Archives/edgar/data/0000320193/000032019317000070/a10-k20179302017.htm', filing_details_filename='filing-details.html'),\n",
       " FilingMetadata(cik='0000320193', file_date='2021-10-29', period_end='2021-09-25', accession_number='0000320193-21-000105', full_submission_url='https://www.sec.gov/Archives/edgar/data/0000320193/000032019321000105/0000320193-21-000105.txt', filing_details_url='https://www.sec.gov/Archives/edgar/data/0000320193/000032019321000105/a10-kexhibit419252021.htm', filing_details_filename='filing-details.html'),\n",
       " FilingMetadata(cik='0000320193', file_date='2012-10-31', period_end='2012-09-29', accession_number='0001193125-12-444068', full_submission_url='https://www.sec.gov/Archives/edgar/data/0000320193/000119312512444068/0001193125-12-444068.txt', filing_details_url='https://www.sec.gov/Archives/edgar/data/0000320193/000119312512444068/d411355d10k.htm', filing_details_filename='filing-details.html'),\n",
       " FilingMetadata(cik='0000320193', file_date='2016-10-26', period_end='2016-09-24', accession_number='0001628280-16-020309', full_submission_url='https://www.sec.gov/Archives/edgar/data/0000320193/000162828016020309/0001628280-16-020309.txt', filing_details_url='https://www.sec.gov/Archives/edgar/data/0000320193/000162828016020309/a201610-k9242016.htm', filing_details_filename='filing-details.html'),\n",
       " FilingMetadata(cik='0000320193', file_date='2019-10-31', period_end='2019-09-28', accession_number='0000320193-19-000119', full_submission_url='https://www.sec.gov/Archives/edgar/data/0000320193/000032019319000119/0000320193-19-000119.txt', filing_details_url='https://www.sec.gov/Archives/edgar/data/0000320193/000032019319000119/a10-k20199282019.htm', filing_details_filename='filing-details.html'),\n",
       " FilingMetadata(cik='0000320193', file_date='2022-10-28', period_end='2022-09-24', accession_number='0000320193-22-000108', full_submission_url='https://www.sec.gov/Archives/edgar/data/0000320193/000032019322000108/0000320193-22-000108.txt', filing_details_url='https://www.sec.gov/Archives/edgar/data/0000320193/000032019322000108/aapl-20220924.htm', filing_details_filename='filing-details.html'),\n",
       " FilingMetadata(cik='0000320193', file_date='2022-10-28', period_end='2022-09-24', accession_number='0000320193-22-000108', full_submission_url='https://www.sec.gov/Archives/edgar/data/0000320193/000032019322000108/0000320193-22-000108.txt', filing_details_url='https://www.sec.gov/Archives/edgar/data/0000320193/000032019322000108/a10-kexhibit4109242022.htm', filing_details_filename='filing-details.html'),\n",
       " FilingMetadata(cik='0000320193', file_date='2014-10-27', period_end='2014-09-27', accession_number='0001193125-14-383437', full_submission_url='https://www.sec.gov/Archives/edgar/data/0000320193/000119312514383437/0001193125-14-383437.txt', filing_details_url='https://www.sec.gov/Archives/edgar/data/0000320193/000119312514383437/d783162d10k.htm', filing_details_filename='filing-details.html'),\n",
       " FilingMetadata(cik='0000320193', file_date='2020-10-30', period_end='2020-09-26', accession_number='0000320193-20-000096', full_submission_url='https://www.sec.gov/Archives/edgar/data/0000320193/000032019320000096/0000320193-20-000096.txt', filing_details_url='https://www.sec.gov/Archives/edgar/data/0000320193/000032019320000096/a10-kexhibit419262020.htm', filing_details_filename='filing-details.html'),\n",
       " FilingMetadata(cik='0000320193', file_date='2021-10-29', period_end='2021-09-25', accession_number='0000320193-21-000105', full_submission_url='https://www.sec.gov/Archives/edgar/data/0000320193/000032019321000105/0000320193-21-000105.txt', filing_details_url='https://www.sec.gov/Archives/edgar/data/0000320193/000032019321000105/aapl-20210925.htm', filing_details_filename='filing-details.html'),\n",
       " FilingMetadata(cik='0000320193', file_date='2020-10-30', period_end='2020-09-26', accession_number='0000320193-20-000096', full_submission_url='https://www.sec.gov/Archives/edgar/data/0000320193/000032019320000096/0000320193-20-000096.txt', filing_details_url='https://www.sec.gov/Archives/edgar/data/0000320193/000032019320000096/aapl-20200926.htm', filing_details_filename='filing-details.html'),\n",
       " FilingMetadata(cik='0000320193', file_date='2019-10-31', period_end='2019-09-28', accession_number='0000320193-19-000119', full_submission_url='https://www.sec.gov/Archives/edgar/data/0000320193/000032019319000119/0000320193-19-000119.txt', filing_details_url='https://www.sec.gov/Archives/edgar/data/0000320193/000032019319000119/a10-kexhibit412019.htm', filing_details_filename='filing-details.html'),\n",
       " FilingMetadata(cik='0000320193', file_date='2015-10-28', period_end='2015-09-26', accession_number='0001193125-15-356351', full_submission_url='https://www.sec.gov/Archives/edgar/data/0000320193/000119312515356351/0001193125-15-356351.txt', filing_details_url='https://www.sec.gov/Archives/edgar/data/0000320193/000119312515356351/d17062d10k.htm', filing_details_filename='filing-details.html'),\n",
       " FilingMetadata(cik='0000320193', file_date='2018-11-05', period_end='2018-09-29', accession_number='0000320193-18-000145', full_submission_url='https://www.sec.gov/Archives/edgar/data/0000320193/000032019318000145/0000320193-18-000145.txt', filing_details_url='https://www.sec.gov/Archives/edgar/data/0000320193/000032019318000145/a10-k20189292018.htm', filing_details_filename='filing-details.html')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_filing_urls(\n",
    "    filing_type=\"10-K\",\n",
    "    ticker=\"AAPL\",\n",
    "    num_filings_to_download=10,\n",
    "    after_date=\"2012-01-01\",\n",
    "    before_date=\"2023-01-01\",\n",
    "    include_amends=True,\n",
    "    query=\"AAPL\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **最後執行**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 獲取當前工作目錄\n",
    "cwd = Path.cwd()\n",
    "\n",
    "# 設定下載目錄\n",
    "downloader = Path(r\"/Users/andrewhsu/Documents/fintech_10_K/intel\")\n",
    "\n",
    "# 調用函數下載指定的 10-K 申報文件\n",
    "download_filings(\n",
    "    downloader,\n",
    "    \"AAPL\",\n",
    "    \"10-K\",\n",
    "    10,  # 下載的文件數量\n",
    "    \"2012-01-01\",  # 開始日期\n",
    "    \"2023-01-01\",  # 結束日期\n",
    "    include_filing_details=True  # 包含詳細文件\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Part3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re  # 匹配正則表達式\n",
    "import glob  # 用於文件匹配\n",
    "from bs4 import BeautifulSoup  # 用於解析 HTML\n",
    "import csv  # 用於 CSV 操作\n",
    "from pathlib import Path  # 用於文件路徑操作\n",
    "\n",
    "# 獲取所有 HTML 文件的路徑\n",
    "files = glob.glob(r\"/Users/andrewhsu/Documents/fintech_10_K/test/AAPL/10-K/**/*.html\", recursive=True)\n",
    "\n",
    "def parser(text, section):\n",
    "    \"\"\"解析文本以提取特定的項目\"\"\"\n",
    "    \n",
    "    def extract_text(text, item_start, item_end):\n",
    "        \"\"\"根據起始和結束標記提取文本\"\"\"\n",
    "        starts = [i.start() for i in item_start.finditer(text)]  # 找到所有起始標記的位置\n",
    "        ends = [i.start() for i in item_end.finditer(text)]  # 找到所有結束標記的位置\n",
    "        positions = list()\n",
    "        \n",
    "        # 構建起始和結束標記之間的範圍\n",
    "        for s in starts:\n",
    "            control = 0\n",
    "            for e in ends:\n",
    "                if control == 0:\n",
    "                    if s < e:\n",
    "                        control = 1\n",
    "                        positions.append([s, e])  # 保存範圍\n",
    "        \n",
    "        item_length = 0\n",
    "        item_position = list()\n",
    "        # 找到最大長度的項目範圍\n",
    "        for p in positions:\n",
    "            if (p[1] - p[0]) > item_length:\n",
    "                item_length = p[1] - p[0]\n",
    "                item_position = p\n",
    "        \n",
    "        # 提取文本\n",
    "        item_text = text[item_position[0]:item_position[1]]\n",
    "        return item_text\n",
    "\n",
    "    # 預設提取的文本\n",
    "    businessText = riskText = mdaText = \"Something went wrong!\"\n",
    "\n",
    "    # 根據 section 提取相應的項目\n",
    "    if section == 1 or section == 0:\n",
    "        try:\n",
    "            item1_start = re.compile(\"item\\s*[1][\\.\\;\\:\\-\\_]*\\s*\\\\b\", re.IGNORECASE)\n",
    "            item1_end = re.compile(\"item\\s*1a[\\.\\;\\:\\-\\_]\\s*Risk|item\\s*2[\\.\\,\\;\\:\\-\\_]\\s*Prop\", re.IGNORECASE)\n",
    "            businessText = extract_text(text, item1_start, item1_end)  # 提取 Item 1\n",
    "        except:\n",
    "            businessText = \"Something went wrong!\"  # 捕捉異常\n",
    "\n",
    "    if section == 2 or section == 0:\n",
    "        try:\n",
    "            item1a_start = re.compile(\"(?<!,\\s)item\\s*1a[\\.\\;\\:\\-\\_]\\s*Risk\", re.IGNORECASE)\n",
    "            item1a_end = re.compile(\"item\\s*2[\\.\\;\\:\\-\\_]\\s*Prop|item\\s*[1]b[\\.\\;\\:\\-\\_]*\\s*\\\\b\", re.IGNORECASE)\n",
    "            riskText = extract_text(text, item1a_start, item1a_end)  # 提取 Item 1A\n",
    "        except:\n",
    "            riskText = \"Something went wrong!\"\n",
    "\n",
    "    if section == 3 or section == 0:\n",
    "        try:\n",
    "            item7_start = re.compile(\"item\\s*[7][\\.\\;\\:\\-\\_]*\\s*\\\\bM\", re.IGNORECASE)\n",
    "            item7_end = re.compile(\"item\\s*7a[\\.\\;\\:\\-\\_]\\sQuanti|item\\s*8[\\.\\,\\;\\:\\-\\_]\\s*\", re.IGNORECASE)\n",
    "            mdaText = extract_text(text, item7_start, item7_end)  # 提取 Item 7\n",
    "        except:\n",
    "            mdaText = \"Something went wrong!\"\n",
    "\n",
    "    # 根據 section 返回對應的數據\n",
    "    if section == 0:\n",
    "        data = [businessText, riskText, mdaText]\n",
    "    elif section == 1:\n",
    "        data = [businessText]\n",
    "    elif section == 2:\n",
    "        data = [riskText]\n",
    "    elif section == 3:\n",
    "        data = [mdaText]\n",
    "    \n",
    "    return data\n",
    "\n",
    "def save_output(parent_dir, index, output):\n",
    "    \"\"\"保存提取的項目到文件中\"\"\"\n",
    "    item_names = [\"Item1\", \"Item1a\", \"Item7\"]  # 項目名稱列表\n",
    "    for item_name, content in zip(item_names, output):\n",
    "        savepath = Path(parent_dir, f\"{index}_{item_name}.txt\")  # 設定保存路徑\n",
    "        with open(savepath, 'w', newline='', encoding=\"utf-8\") as outfile:\n",
    "            outfile.write(content)  # 寫入文件\n",
    "\n",
    "# 設定保存的父目錄路徑\n",
    "parent_dir = r\"/Users/andrewhsu/Documents/fintech_10_K/test/AAPL/保存columns\"\n",
    "\n",
    "# 遍歷所有文件並提取內容\n",
    "for i, file_path in enumerate(files):\n",
    "    with open(file_path, encoding='utf-8') as f:\n",
    "        soup = BeautifulSoup(f.read(), features=\"html.parser\")\n",
    "        for script in soup([\"script\", \"style\"]):\n",
    "            script.extract()  # 移除 script 和 style 標籤\n",
    "        text = soup.get_text()  # 提取純文本\n",
    "\n",
    "        # 抓取所有項目\n",
    "        output = parser(text, 0)\n",
    "\n",
    "        # 保存提取的項目\n",
    "        save_output(parent_dir, i, output)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
